{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Course-week1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM4ThnMzQ+FCjRbdRzIa8G0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramenwang/deep_learning_py/blob/master/Coursera/NLP/NLP_Course_week1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IqoGeSicXZK",
        "colab_type": "text"
      },
      "source": [
        "# Text Tokenizer Basic\n",
        "* tokenize text\n",
        "* text to sequence methods to tokenize sentences\n",
        "* create special token for out-of-vocabulary text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRYItzGhb-pW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "66b3531c-a0e5-4fb5-cf12-74ee9fd55de5"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loabn5sEcPlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = [\n",
        "             'I love my dog',\n",
        "             'I love my cat',\n",
        "             'You love my Dog!',\n",
        "             'Do you think Ziyang is amazing?'\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100) # the top 100 words in terms of its volumns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqrctAwc2Dd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3616ed27-cd58-4ecf-db76-9540ead63ab8"
      },
      "source": [
        "tokenizer.fit_on_texts(sentences)\n",
        "tokenizer.word_index"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'amazing': 11,\n",
              " 'cat': 6,\n",
              " 'do': 7,\n",
              " 'dog': 4,\n",
              " 'i': 3,\n",
              " 'is': 10,\n",
              " 'love': 1,\n",
              " 'my': 2,\n",
              " 'think': 8,\n",
              " 'you': 5,\n",
              " 'ziyang': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzZUoQGEdD5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4376e895-5f79-4d9e-9818-81b836e46e65"
      },
      "source": [
        "# text to sequences\n",
        "tokenizer.texts_to_sequences(sentences)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 1, 2, 4], [3, 1, 2, 6], [5, 1, 2, 4], [7, 5, 8, 9, 10, 11]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jQ7Fx3fexOK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02aa9d35-042c-4dcf-d4de-6882057306f5"
      },
      "source": [
        "sentences_2 = {\n",
        "    'Ziyang is a da sha bi~',\n",
        "    'Ziyang loves dog',\n",
        "    'Ziyang love dog'\n",
        "}\n",
        "tokenizer.texts_to_sequences(sentences_2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[9, 4], [9, 1, 4], [9, 10]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqwIQGVse3Ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6b53e385-cd90-4cc9-a630-5cb393c1d9d0"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=100, oov_token='<OOV>') # with oov\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "tokenizer.word_index"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<OOV>': 1,\n",
              " 'amazing': 12,\n",
              " 'cat': 7,\n",
              " 'do': 8,\n",
              " 'dog': 5,\n",
              " 'i': 4,\n",
              " 'is': 11,\n",
              " 'love': 2,\n",
              " 'my': 3,\n",
              " 'think': 9,\n",
              " 'you': 6,\n",
              " 'ziyang': 10}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPEvEDBFgPdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "789cd54d-dec6-4b8d-ffe1-8f447c2f4c8e"
      },
      "source": [
        "tokenizer.texts_to_sequences(sentences_2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 1, 5], [10, 2, 5], [10, 11, 1, 1, 1, 1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOWxBvhhgXur",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5624f1db-2065-422d-bf3b-5823c3cede39"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# pad sequences to same length\n",
        "seq_2 = tokenizer.texts_to_sequences(sentences_2)\n",
        "pad_sequences(seq_2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, 10,  1,  5],\n",
              "       [ 0,  0,  0, 10,  2,  5],\n",
              "       [10, 11,  1,  1,  1,  1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj-jTgZSmQFe",
        "colab_type": "text"
      },
      "source": [
        "The padding in default happens in the front of the sequence, but one can change it by setting **padding='post'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLMyM1lWmKyw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7299cd34-c722-4dca-d766-485de6edbe10"
      },
      "source": [
        "pad_sequences(seq_2, padding='post')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  1,  5,  0,  0,  0],\n",
              "       [10,  2,  5,  0,  0,  0],\n",
              "       [10, 11,  1,  1,  1,  1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90WmVNU3msDP",
        "colab_type": "text"
      },
      "source": [
        "One can also define the width of the padding; otherwise, in default, the padding will define the width as the maximum sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfBQCJqNmqOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "22763df6-25b9-4e1a-83da-129a8a41b4a3"
      },
      "source": [
        "pad_sequences(seq_2, padding='post',maxlen=3)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  1,  5],\n",
              "       [10,  2,  5],\n",
              "       [ 1,  1,  1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJkX1pxOomte",
        "colab_type": "text"
      },
      "source": [
        "While shrunkening the paded sequence using maxlen, the default truncating happends at the back"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW81--DAnHse",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "97bd7adf-54b7-42c0-d05c-e180372cacfd"
      },
      "source": [
        "pad_sequences(seq_2, maxlen=3, padding='post', truncating='post')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  1,  5],\n",
              "       [10,  2,  5],\n",
              "       [10, 11,  1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEjs4n2ApCde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}