{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RSSuperRes_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNDeBFvjNESrjymWtYBfxpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramenwang/deep_learning_py/blob/master/super_resolution/RSSuperRes_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-1kyzZtukuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0b109ec1-be1e-4a71-a497-f6748e6d5c42"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import Concatenate, Conv2D, LeakyReLU, Dense, Lambda\n",
        "from keras.layers import BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT2nynvXw3RU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def conv2d(x, num_filter, filter_size, stride=(1,1), padding='same', name=None,\n",
        "           act=True, batchnorm=True, dropout_rate=None):\n",
        "    ''' conv2d with optional batchnorm, leakyReLU activation, or dropout\n",
        "    '''\n",
        "    x = Conv2D(filters=num_filter, kernel_size=filter_size, strides=stride,\n",
        "               padding=padding, name=name+'_conv2d')(x)\n",
        "    # batch normalization\n",
        "    if (batchnorm):\n",
        "        x = BatchNormalization(name=name+'_conv2d_bn')(x)\n",
        "    # activation\n",
        "    if (act):\n",
        "        x = LeakyReLU(name=name+'_conv2d_leakyReLU')(x)\n",
        "    # random dropout\n",
        "    if (dropout_rate != None):\n",
        "        x = Dropout(rate=dropout_rate)(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def inception_module(x, nin_filter1, nin_filter2, dropout_rate):\n",
        "    ''' inception layer with bottleneck layer to reduce the depth\n",
        "    '''\n",
        "    # path 1 - bottleneck layer\n",
        "    p1 = conv2d(x, num_filter=nin_filter1, filter_size=(1,1), name='Inc_path_1_bn',\n",
        "                act=True, batchnorm=True, dropout_rate=dropout_rate)\n",
        "    # path 2 - bottleneck layer + 3*3 filter\n",
        "    p2 = conv2d(x, num_filter=nin_filter1, filter_size=(1,1), name='Inc_path_2_bn',\n",
        "                act=True, batchnorm=True, dropout_rate=dropout_rate)\n",
        "    p2 = conv2d(p2, num_filter=nin_filter1, filter_size=(3,3), name='Inc_path_2_conv',\n",
        "                act=True, batchnorm=True, dropout_rate=dropout_rate)\n",
        "    # path 3 - bottleneck layer + 3*3 filter\n",
        "    p3 = conv2d(x, num_filter=nin_filter1, filter_size=(1,1), name='Inc_path_3_bn',\n",
        "                act=True, batchnorm=True, dropout_rate=dropout_rate)\n",
        "    p3 = conv2d(p3, num_filter=nin_filter1, filter_size=(5,5), name='Inc_path_3_conv',\n",
        "                act=True, batchnorm=True, dropout_rate=dropout_rate)\n",
        "    \n",
        "    output = Concatenate([p_1, p_2, p_3], axis=3, name='Inc_concat')\n",
        "    return output\n",
        "    \n",
        "\n",
        "def pixel_shuffler(x, scale, output_filters, filter_size):\n",
        "    ''' pixel shuffler layer to reconstruct the 2d space from feature map channels\n",
        "    '''\n",
        "    ps = conv2d(x, num_filter=output_filters*scale*scale, filter_size=filter_size,\n",
        "                name='ps', batchnorm=False, act=False, dropout_rate=None)\n",
        "    # using depth_to_space to resampling the image pixel from depth\n",
        "    Subpixel_layer = Lambda(lambda x: tf.nn.depth_to_space(x,scale))\n",
        "    ps = Subpixel_layer(inputs=ps)\n",
        "    ps = LeakyReLU(name='ps_conv2d_leakyReLU')(ps)\n",
        "    return ps\n",
        "    \n",
        "\n",
        "def feature_extractor(x, n_layers, filter_size, n_filter, min_filters, \n",
        "                      filter_decay_gamma, dropout_rate):\n",
        "    ''' building feature extractor with skip connection and filter gamma decay\n",
        "    '''\n",
        "    concat_list = []\n",
        "    n_filter_list = []\n",
        "    for i in range(n_layers):\n",
        "        # perform gamma decay\n",
        "        if min_filters !=0 and i > 0:\n",
        "            x1 = i / float(n_layers - 1)\n",
        "            y1 = pow(x1, 1. / filter_decay_gamma)\n",
        "            n_filters = int((n_filters - min_filters) * (1 - y1) + min_filters)\n",
        "            n_filter_list.append(n_filters)\n",
        "        # perform convolution\n",
        "        x = conv2(x, num_filter=n_filters, filter_size=filter_size, name='FE_'+str(i),\n",
        "                  act=True, batchnorm=True, dropout_rate=dropout_rate)\n",
        "        concat_list.append(x)\n",
        "\n",
        "    output = Concatenate(concat_list, axis=3, name='FE_concat')\n",
        "    return output, n_filter_list\n",
        "\n",
        "\n",
        "def RSSuperRes(x, bicubic_x, n_layers, min_filters, filter_decay_gamma, \n",
        "               dropout_rate, n_reconstructors, num_recon_filter, output_channels):\n",
        "    ''' super resolution model\n",
        "    '''\n",
        "    x = feature_extractor(x=x, n_layers, filter_size=3, n_filter, min_filters, \n",
        "                          filter_decay_gamma, dropout_rate)\n",
        "    x = inception_module(x=x, nin_filter1=nin_filter1, nin_filter2=nin_filter2,\n",
        "                         dropout_rate=dropout_rate)\n",
        "    x = pixel_shuffler(x=x, scale=scale, output_filters=output_filters,\n",
        "                       filter_size=filter_size)\n",
        "    for i in range(max(1, n_reconstructors)):\n",
        "        x = conv2d(x=x, num_filter=num_recon_filter, filter_size=filter_size, batchnorm=False,\n",
        "                   dropout_rate=dropout_rate)\n",
        "    x = conv2d(x=x, num_filter=output_channels, filter_size=filter_size, batchnorm=False,\n",
        "               dropout_rate=dropout_rate, act=False, name='output')\n",
        "\n",
        "    x = x + bicubic_x\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgmsWp-_xBxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81c22158-34d4-4aac-fb8b-4d6071cb38e8"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vyCKgcNwbOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}