{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Simple Dataset</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this lab, you will construct a basic dataset by using PyTorch and learn how to apply basic transformations to it.</p> \n",
    "<ul>\n",
    "    <li><a href=\"#Simple_Dataset\">Simple dataset</a></li>\n",
    "    <li><a href=\"#Transforms\">Transforms</a></li>\n",
    "    <li><a href=\"#Compose\">Compose</a></li>\n",
    "</ul>\n",
    "<p>Estimated Time Needed: <strong>30 min</strong></p>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f13765620d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Simple_Dataset\">Simple dataset</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to create our own dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toy_set(Dataset):\n",
    "    \n",
    "    def __init__(self, length=100, transform=None):\n",
    "        self.len = length\n",
    "        self.x = 2 * torch.ones(length, 2)\n",
    "        self.y = torch.ones(length)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create our <code>toy_set</code> object, and find out the value on index 1 and the length of the inital dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our toy_set object:  <__main__.toy_set object at 0x7f1376018c50>\n",
      "Value on index 0 of our toy_set object:  (tensor([2., 2.]), tensor(1.))\n",
      "Our toy_set length:  100\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset Object. Find out the value on index 1. Find out the length of Dataset Object.\n",
    "\n",
    "our_dataset = toy_set()\n",
    "print(\"Our toy_set object: \", our_dataset)\n",
    "print(\"Value on index 0 of our toy_set object: \", our_dataset[0])\n",
    "print(\"Our toy_set length: \", len(our_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we can apply the same indexing convention as a <code>list</code>,\n",
    "and apply the fuction <code>len</code> on the <code>toy_set</code> object. We are able to customize the indexing and length method by <code>def &#95;&#95;getitem&#95;&#95;(self, index)</code> and <code>def &#95;&#95;len&#95;&#95;(self)</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us print out the first 3 elements and assign them to x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  0 ; x: tensor([2., 2.]) ; y: tensor(1.)\n",
      "index:  1 ; x: tensor([2., 2.]) ; y: tensor(1.)\n",
      "index:  2 ; x: tensor([2., 2.]) ; y: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Use loop to print out first 3 elements in dataset\n",
    "\n",
    "for i in range(3):\n",
    "    x, y=our_dataset[i]\n",
    "    print(\"index: \", i, '; x:', x, '; y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset object is an Iterable; as a result, we  apply the loop directly on the dataset object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n",
      " x: tensor([2., 2.]) y: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for x,y in our_dataset:\n",
    "    print(' x:', x, 'y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to create an <code>toy_set</code> object with length <b>50</b>. Print out the length of your object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.5330, 0.0512, 0.0910], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.7819,  1.7683, -0.5925], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.5654, -1.2602,  2.2674], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-3.2757,  0.6825, -0.1373], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.0192, -1.0548,  1.0375], dtype=torch.float64), tensor(1.))\n",
      "(tensor([1.4275, 0.6658, 1.3370], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.4302, -1.2164,  0.3377], dtype=torch.float64), tensor(1.))\n",
      "(tensor([0.3932, 0.5788, 1.8006], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.1507,  0.2461, -0.1819], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.2164,  0.2298, -0.6445], dtype=torch.float64), tensor(1.))\n",
      "(tensor([0.7411, 0.3782, 0.1760], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.2896, -0.1323, -0.2513], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.6379, -1.7868, -0.8313], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.0394,  1.0348,  1.8472], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.9431, -0.2105,  1.2456], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.3907, -1.6971,  0.4014], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 2.0448, -0.7412,  0.8458], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-1.3571,  1.1827,  2.1366], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.7085,  0.4366,  2.1390], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-1.3251,  0.2843,  2.1926], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.1530, -0.0981, -1.9932], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.4851, -0.1463, -0.4503], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.2992,  0.9013, -0.0378], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-3.2644,  0.2002, -0.6430], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 2.3658, -1.1460, -2.0819], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-1.0487, -1.3421,  0.5247], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-1.9388, -0.0754,  1.1176], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.1404, -0.1997, -0.4463], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-2.3933, -0.1486,  0.6443], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.7060, -0.7791, -1.4971], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.7652, -0.4585, -1.0523], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.1573, -0.1403,  0.5383], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.7927, -0.2447, -0.8488], dtype=torch.float64), tensor(1.))\n",
      "(tensor([0.3931, 0.3911, 0.0507], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 1.0469, -0.8969, -1.8124], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.5298, -1.1629, -0.2940], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.6620,  0.2660, -2.3861], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.7046, -0.5858, -0.9585], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.0850,  0.6694, -0.6012], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.7238, -0.2406, -0.3943], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.5236,  1.9372, -0.0645], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.6155,  0.2758,  0.5975], dtype=torch.float64), tensor(1.))\n",
      "(tensor([0.1958, 0.3058, 0.5298], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.7427, -0.1295,  0.0811], dtype=torch.float64), tensor(1.))\n",
      "(tensor([1.1438, 1.1606, 0.5215], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.5463, -0.6576,  1.6624], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.1208,  0.1071, -0.2146], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 1.4170, -1.9891,  0.2035], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-0.1392,  0.1901,  0.9893], dtype=torch.float64), tensor(1.))\n",
      "(tensor([ 0.3740, -0.7349, -0.8138], dtype=torch.float64), tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "# Practice: Create a new object with length 50, and print the length of object out.\n",
    "\n",
    "# Type your code here\n",
    "from numpy.random import randn\n",
    "\n",
    "class toy_set(Dataset):\n",
    "    \n",
    "    def __init__(self, length, transform=None):\n",
    "        self.len = length\n",
    "        self.x = torch.from_numpy(randn(length, 3))\n",
    "        self.y = torch.ones(length)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "new_data = toy_set(length=50)\n",
    "for x, y in new_data:\n",
    "    print((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!-- \n",
    "my_dataset = toy_set(length = 50)\n",
    "print(\"My toy_set length: \", len(my_dataset))\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Transforms\">Transforms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create a class for transforming the data. In this case, we will try to add 1 to x and multiply y by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class add_mul(object):\n",
    "    \n",
    "    def __init__(self, add_x, mul_y):\n",
    "        self.add_x = add_x\n",
    "        self.mul_y = mul_y\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        return sample[0] + self.add_x, sample[1] * self.mul_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a transform object:."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an add_mult transform object, and an toy_set object\n",
    "\n",
    "a_m = add_mul(add_x=2, mul_y=3)\n",
    "data_set = toy_set(length=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the outputs of the original dataset to <code>x</code> and <code>y</code>. Then, apply the transform <code>add_mult</code> to the dataset and output the values as <code>x_</code> and <code>y_</code>, respectively: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0 Original x:  tensor([-0.4663,  1.1305,  0.1548], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  0 Transformed x_: tensor([1.5337, 3.1305, 2.1548], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  1 Original x:  tensor([-0.7209,  0.4311,  0.6368], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  1 Transformed x_: tensor([1.2791, 2.4311, 2.6368], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  2 Original x:  tensor([-0.5333, -0.5936,  1.2296], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  2 Transformed x_: tensor([1.4667, 1.4064, 3.2296], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  3 Original x:  tensor([-1.4864,  1.8422,  1.9957], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  3 Transformed x_: tensor([0.5136, 3.8422, 3.9957], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  4 Original x:  tensor([ 0.9255, -1.9691, -2.1971], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  4 Transformed x_: tensor([ 2.9255,  0.0309, -0.1971], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  5 Original x:  tensor([-0.4701, -1.5679,  0.5110], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  5 Transformed x_: tensor([1.5299, 0.4321, 2.5110], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  6 Original x:  tensor([-0.4611, -1.8344,  1.5309], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  6 Transformed x_: tensor([1.5389, 0.1656, 3.5309], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  7 Original x:  tensor([-0.0879, -0.6785, -0.2023], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  7 Transformed x_: tensor([1.9121, 1.3215, 1.7977], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  8 Original x:  tensor([ 0.0664,  0.6695, -0.9753], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  8 Transformed x_: tensor([2.0664, 2.6695, 1.0247], dtype=torch.float64) Transformed y_: tensor(3.)\n",
      "Index:  9 Original x:  tensor([ 0.9644, -1.4474,  0.5864], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  9 Transformed x_: tensor([2.9644, 0.5526, 2.5864], dtype=torch.float64) Transformed y_: tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# Use loop to print out first 10 elements in dataset\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = a_m(data_set[i])\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result, <code>x</code> has been added by 1 and y has been multiplied by 2, as <i>[2, 2] + 1 = [3, 3]</i> and <i>[1] x 2 = [2]</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply the transform object every time we create a new <code>toy_set object</code>? Remember, we have the constructor in toy_set class with the parameter <code>transform = None</code>.\n",
    "When we create a new object using the constructor, we can assign the transform object to the parameter transform, as the following code demonstrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data_set object with add_mult object as transform\n",
    "\n",
    "cust_data_set = toy_set(length=20, transform = a_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This applied <code>a_m</code> object (a transform method) to every element in <code>cust_data_set</code> as initialized. Let us print out the first 10 elements in <code>cust_data_set</code> in order to see whether the <code>a_m</code> applied on <code>cust_data_set</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0 Original x:  tensor([-0.4663,  1.1305,  0.1548], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  0 Transformed x_: tensor([0.3462, 0.5173, 1.2921], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  1 Original x:  tensor([-0.7209,  0.4311,  0.6368], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  1 Transformed x_: tensor([0.6977, 0.0045, 0.0832], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  2 Original x:  tensor([-0.5333, -0.5936,  1.2296], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  2 Transformed x_: tensor([-0.8482, -1.0351,  0.2825], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  3 Original x:  tensor([-1.4864,  1.8422,  1.9957], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  3 Transformed x_: tensor([0.5943, 1.3780, 0.2331], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  4 Original x:  tensor([ 0.9255, -1.9691, -2.1971], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  4 Transformed x_: tensor([-0.5493, -1.8604, -2.1417], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  5 Original x:  tensor([-0.4701, -1.5679,  0.5110], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  5 Transformed x_: tensor([-0.5617,  0.4827,  1.3461], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  6 Original x:  tensor([-0.4611, -1.8344,  1.5309], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  6 Transformed x_: tensor([1.1882, 1.1458, 0.6262], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  7 Original x:  tensor([-0.0879, -0.6785, -0.2023], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  7 Transformed x_: tensor([0.4195, 2.4323, 0.3838], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  8 Original x:  tensor([ 0.0664,  0.6695, -0.9753], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  8 Transformed x_: tensor([-0.7567,  0.1769, -0.6378], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  9 Original x:  tensor([ 0.9644, -1.4474,  0.5864], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  9 Transformed x_: tensor([-0.5509,  0.0922, -1.7135], dtype=torch.float64) Transformed y_: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Use loop to print out first 10 elements in dataset\n",
    "\n",
    "for i in range(10):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = cust_data_set[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the same as the previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Construct your own my_add_mult transform. Apply my_add_mult on a new toy_set object. Print out the first three elements from the transformed dataset.\n",
    "\n",
    "# Type your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!-- \n",
    "class my_add_mult(object):   \n",
    "    def __init__(self, add = 2, mul = 10):\n",
    "        self.add=add\n",
    "        self.mul=mul\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x + self.add\n",
    "        y = y + self.add\n",
    "        x = x * self.mul\n",
    "        y = y * self.mul\n",
    "        sample = x, y\n",
    "        return sample\n",
    "        \n",
    "       \n",
    "my_dataset = toy_set(transform = my_add_mult())\n",
    "for i in range(3):\n",
    "    x_, y_ = my_dataset[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)\n",
    "    \n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Compose\">Compose</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compose multiple transforms on the dataset object. First, import <code>transforms</code> from <code>torchvision</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the command below when you do not have torchvision installed\n",
    "# !conda install -y torchvision\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a new transform class that multiplies each of the elements by 100: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tranform class mult\n",
    "\n",
    "class mult(object):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, mult = 100):\n",
    "        self.mult = mult\n",
    "        \n",
    "    # Executor\n",
    "    def __call__(self, sample):\n",
    "        x = sample[0]\n",
    "        y = sample[1]\n",
    "        x = x * self.mult\n",
    "        y = y * self.mult\n",
    "        sample = x, y\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to combine the transforms <code>add_mult</code> and <code>mult</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combination of transforms (Compose):  Compose(\n",
      "    <__main__.add_mul object at 0x7f1375cf8588>\n",
      "    <__main__.mult object at 0x7f1375cf87f0>\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Combine the add_mult() and mult()\n",
    "\n",
    "data_transform = transforms.Compose([add_mul(add_x=3, mul_y=4), mult()])\n",
    "print(\"The combination of transforms (Compose): \", data_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new <code>Compose</code> object will perform each transform concurrently as shown in this figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/1.3.1_trasform.png\" width=\"500\" alt=\"Compose PyTorch\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([253.3713, 413.0548, 315.4776], dtype=torch.float64), tensor(400.))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transform(data_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original x:  tensor([-0.4663,  1.1305,  0.1548], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Transformed x_: tensor([253.3713, 413.0548, 315.4776], dtype=torch.float64) Transformed y_: tensor(400.)\n"
     ]
    }
   ],
   "source": [
    "x,y=data_set[0]\n",
    "x_,y_=data_transform(data_set[0])\n",
    "print( 'Original x: ', x, 'Original y: ', y)\n",
    "\n",
    "print( 'Transformed x_:', x_, 'Transformed y_:', y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pass the new <code>Compose</code> object (The combination of methods <code>add_mult()</code> and <code>mult</code>) to the constructor for creating <code>toy_set</code> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new toy_set object with compose object as transform\n",
    "\n",
    "compose_data_set = toy_set(length=20,transform = data_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us print out the first 3 elements in different <code>toy_set</code> datasets in order to compare the output after different transforms have been applied: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0 Original x:  tensor([-0.4663,  1.1305,  0.1548], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  0 Transformed x_: tensor([0.3462, 0.5173, 1.2921], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  0 Compose Transformed x_co:  tensor([ 0.9376,  0.3512, -0.3920], dtype=torch.float64) Compose Transformed y_co:  tensor(1.)\n",
      "Index:  1 Original x:  tensor([-0.7209,  0.4311,  0.6368], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  1 Transformed x_: tensor([0.6977, 0.0045, 0.0832], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  1 Compose Transformed x_co:  tensor([-0.7086,  0.0253, -1.4833], dtype=torch.float64) Compose Transformed y_co:  tensor(1.)\n",
      "Index:  2 Original x:  tensor([-0.5333, -0.5936,  1.2296], dtype=torch.float64) Original y:  tensor(1.)\n",
      "Index:  2 Transformed x_: tensor([-0.8482, -1.0351,  0.2825], dtype=torch.float64) Transformed y_: tensor(1.)\n",
      "Index:  2 Compose Transformed x_co:  tensor([ 2.0352,  1.1366, -1.7693], dtype=torch.float64) Compose Transformed y_co:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# Use loop to print out first 3 elements in dataset\n",
    "\n",
    "for i in range(3):\n",
    "    x, y = data_set[i]\n",
    "    print('Index: ', i, 'Original x: ', x, 'Original y: ', y)\n",
    "    x_, y_ = cust_data_set[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)\n",
    "    x_co, y_co = compose_data_set[i]\n",
    "    print('Index: ', i, 'Compose Transformed x_co: ', x_co ,'Compose Transformed y_co: ',y_co)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what happened on index 0. The original value of <code>x</code> is <i>[2, 2]</i>, and the original value of <code>y</code> is [1]. If we only applied <code>add_mult()</code> on the original dataset, then the <code>x</code> became <i>[3, 3]</i> and y became <i>[2]</i>. Now let us see what is the value after applied both <code>add_mult()</code> and <code>mult()</code>. The result of x is <i>[300, 300]</i> and y is <i>[200]</i>. The calculation which is equavalent to the compose is <i> x = ([2, 2] + 1) x 100 = [300, 300], y = ([1] x 2) x 100 = 200</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to combine the <code>mult()</code> and <code>add_mult()</code> as <code>mult()</code> to be executed first. And apply this on a new <code>toy_set</code> dataset. Print out the first 3 elements in the transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 0.9254, -0.0984, -1.1893], dtype=torch.float64), tensor(1.))\n",
      "(tensor([-1.4233, -1.6722,  0.5870], dtype=torch.float64), tensor(1.))\n",
      "(tensor([1.3945, 1.1741, 0.9525], dtype=torch.float64), tensor(1.))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.9254, -0.0984, -1.1893],\n",
       "         [-1.4233, -1.6722,  0.5870],\n",
       "         [ 1.3945,  1.1741,  0.9525]], dtype=torch.float64),\n",
       " tensor([1., 1., 1.]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Practice: Make a compose as mult() execute first and then add_mult(). Apply the compose on toy_set dataset. Print out the first 3 elements in the transformed dataset.\n",
    "\n",
    "# Type your code here.\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "class mult(object):\n",
    "    \n",
    "    def __init__(self, y_mul=2):\n",
    "        self.y_mul = y_mul\n",
    "        \n",
    "    def __call__(self, dt):\n",
    "        return dt[0], dt[1] * self.y_mul\n",
    "    \n",
    "    \n",
    "class add_mul(object):\n",
    "    \n",
    "    def __init__(self, x_add=3, y_mul=10):\n",
    "        self.x_add = x_add\n",
    "        self.y_mul = y_mul\n",
    "        \n",
    "    def __call__(self, dt):\n",
    "        return dt[0]+self.x_add, dt[1]*self.y_mul\n",
    "    \n",
    "    \n",
    "dt_transform = transforms.Compose([mult(), add_mul()])\n",
    "dt = toy_set(length=10, transform=dt_transform)\n",
    "for i in range(3):\n",
    "    print(dt[i])\n",
    "    \n",
    "    \n",
    "dt[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!--\n",
    "my_compose = transforms.Compose([mult(), add_mult()])\n",
    "my_transformed_dataset = toy_set(transform = my_compose)\n",
    "for i in range(3):\n",
    "    x_, y_ = my_transformed_dataset[i]\n",
    "    print('Index: ', i, 'Transformed x_:', x_, 'Transformed y_:', y_)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
